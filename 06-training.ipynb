{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "name": "06-training.ipynb",
    "colab": {
      "name": "06-training.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ac2e80835fda4f0b9d588eac78f134de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6e43488419c14bbd8bc75f2d6c4401ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c1858ad016b44907947a8d65fb12cd2b",
              "IPY_MODEL_9acfbab0a8934f19968e129219d09278"
            ]
          }
        },
        "6e43488419c14bbd8bc75f2d6c4401ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1858ad016b44907947a8d65fb12cd2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ee20fe47600f4e18b3c858451f964ef8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 169001437,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 169001437,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_31be0d57901b4499ab4236b74f24b8da"
          }
        },
        "9acfbab0a8934f19968e129219d09278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_552b74d1ed06449d88f60a1168f991ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169001984/? [00:05&lt;00:00, 30921582.05it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1e8fb860d664edbb3c5749f40f44462"
          }
        },
        "ee20fe47600f4e18b3c858451f964ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "31be0d57901b4499ab4236b74f24b8da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "552b74d1ed06449d88f60a1168f991ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1e8fb860d664edbb3c5749f40f44462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMDcFHeqRcTu"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "- [Training](#train)\n",
        "- [Exercises](#exercises)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uw8GrzfRcTx"
      },
      "source": [
        "# Housekeeping\n",
        "\n",
        "- Some references for today\n",
        "  - [Official pytorch tutorials](https://pytorch.org/tutorials/)\n",
        "  - [Pytorch tutorials by yunjey, from beginning to advanced](https://github.com/yunjey/pytorch-tutorial)\n",
        "  - [MIT Intro to Deep Learning](https://www.youtube.com/watch?v=njKP3FqW3Sk&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&index=1) lecture video \n",
        "    (overview of machine learning and neural networks)\n",
        "  - [Machine Learning Basics](https://www.deeplearningbook.org/contents/ml.html) from the Deep Learning Book \n",
        "    (especially section 5.2 on Capacity, Overfitting and Underfitting)\n",
        "- Today's url \n",
        "  - https://git.io/ml2021-06\n",
        "- Email if you need help with any of this!\n",
        "\n",
        "# Some Preliminary Words on Training <a id=\"training\" />\n",
        "\n",
        "- In the last weeks, we learnt how to create neural networks in pytorch, and\n",
        "  about some of the loss functions and optimizers we are able to use\n",
        "- We saw its easy to take some data, throw a neural network at it and\n",
        "  get it to train\n",
        "- The hard part is developing a *good* model for the data\n",
        "- Neural networks are prone to failure modes we'll discuss today\n",
        "- Its important to understand these failure modes and build *robust*\n",
        "  networks\n",
        "- So, before moving onto the deep learning topics that we'll spend the\n",
        "  rest of the course on, lets stop and talk a bit about training\n",
        "\n",
        "# Generalization\n",
        "\n",
        "- The goal of building a model on known inputs is that we want the\n",
        "  model to *generalize* to unlabelled data\n",
        "- That is, the data should correctly classify data from outside the training set\n",
        "- If the model only works on datapoints in the training, its not much use\n",
        "  - Imagine your a medical expert training a network to detect cancer,\n",
        "    you build a cancer classifier which takes as inputs MRI scans. If\n",
        "    it works correctly on images its seen in the training set\n",
        "    (labelled by doctors based on patient outcomes), but randomly\n",
        "    assigns labels to other images, its not useful to you at all, and\n",
        "    could cost lives!\n",
        "- The goal of this lesson is to figure out how best to train models\n",
        "  that generalize\n",
        "\n",
        "# Undertraining and Overtraining\n",
        "\n",
        "- **Undertraining** is when a model isn't complex enough to be able to\n",
        "  find the trends in the data\n",
        "  - Imagine a regression task where the data follows a quadratic\n",
        "    curve, fitting a linear function won't be able to capture all the information\n",
        "- **Overtraining** is when a model is too complex and it begins fitting\n",
        "  *fluctuations* in the labelled datapoints\n",
        "  - We imagine theres some random errors in the data that can't be\n",
        "    modelled, when a model is overtrained, it takes these random\n",
        "    errors seriously and forms a model for them, which can't\n",
        "    generalize to unseen data\n",
        "\n",
        "As we increase the polynomial order of the fit function, we start to overtrain\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUVkpXccRcTy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "bc4b2abf-ba63-4f68-cca6-c8f6b3feefbe"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "npoints = 50\n",
        "red = torch.stack((torch.randn(npoints), torch.randn(npoints)), axis=1)\n",
        "blue = torch.stack((torch.randn(npoints)+1.5, torch.randn(npoints)+1.5), axis=1)\n",
        "\n",
        "plt.scatter(red[:,0], red[:,1], c='r');plt.scatter(blue[:,0], blue[:,1], c='b')\n",
        "plt.show()\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "  def __init__(self, n):\n",
        "    super(Model, self).__init__()\n",
        "    self.n = n\n",
        "    self.fc1 = torch.nn.Linear(2,n)\n",
        "    self.fc2 = torch.nn.Linear(n,n)\n",
        "    self.fc3 = torch.nn.Linear(n,1)\n",
        "  def forward(self, x):\n",
        "    #x = torch.stack([x**i for i in range(self.n+1)], axis=1)\n",
        "    x = th.relu(self.fc1(x))\n",
        "    x = th.relu(self.fc2(x))\n",
        "    x = th.sigmoid(self.fc3(x))\n",
        "    return x\n",
        "\n",
        "xs = th.cat([red,blue])\n",
        "ys = th.cat([th.ones(len(red)), th.zeros(len(blue))])\n",
        "print(\"UNDERTRAINED?\")\n",
        "\n",
        "def showmodel(n):\n",
        " m = Model(n)\n",
        " lossf = torch.nn.BCELoss()\n",
        " optim = torch.optim.AdamW(m.parameters(),lr=0.01)\n",
        " for _ in range(2500):\n",
        "   optim.zero_grad()\n",
        "   fs = m(xs)\n",
        "   loss = lossf(fs.view(-1), ys)\n",
        "   loss.backward()\n",
        "   optim.step()\n",
        " x1,x2=np.meshgrid(np.linspace(-4,4), np.linspace(-4,4))\n",
        " col = m(th.tensor(np.dstack([x1,x2])).float())\n",
        " plt.imshow(col.detach().numpy(),origin='lower',extent=(-4,4,-4,4), cmap='bwr')\n",
        " plt.scatter(red[:,0], red[:,1], c='r',edgecolor='k');plt.scatter(blue[:,0], blue[:,1], c='b', edgecolor='k')\n",
        " plt.show()\n",
        "showmodel(2)\n",
        "showmodel(8)\n",
        "showmodel(32)\n",
        "showmodel(256)\n",
        "print(\"OVERTRAINED?\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1f536c2e3784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UNDERTRAINED?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'th' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzgASgIWRcT1"
      },
      "source": [
        "# Model Capacity\n",
        "- A model's *capacity* is its ability to fit a wide variety of functions\n",
        "- Models with low capacity might struggle to fit the training set,\n",
        "  while those with high capacity can memorize parts of the training\n",
        "  set that don't generalize, in the extreme just memorizes the entire dataset\n",
        "- Capacity can be controlled in different ways depending on the model\n",
        "- E.g. last week we considered linear regression, we can increase the\n",
        "  capacity by allow higher order terms as new features\n",
        "  - Linear regression models the relationship of $y$ and $x$ by assuming $y = ax + b$\n",
        "  - If we introduce $x^2$ as a feature, we can additionally model\n",
        "    quadratic relationships, $y=ax^2+bx+c$\n",
        "  - The more terms we allow, the more features we can model, but the\n",
        "    greater the chance we memorize datapoints rather than the trends\n",
        "- For our basic neural networks, capacity increases with increasing\n",
        "  number of nodes in the hidden layer, and with increasing number of\n",
        "  layers\n",
        "\n",
        "# The Bias-Variance Tradeoff\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiVmuFufRcT3"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(\"bias-variance.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_h5ufL1RcT3"
      },
      "source": [
        "- *Bias*: the difference between our model prediction and the datapoints\n",
        "  - A high *bias* model has large differences between the datapoints\n",
        "  - A model which doesn't have enough parameters *underfits* the data\n",
        "- *Variance, a measure of the fluctuations of the data or model, high\n",
        "  variance models are typically fitting the intrinsic noise of the data\n",
        "  - A high variance model implies small changes in the input cause large changes in the output\n",
        "  - A high variance model with too many parameters *overfits* the data\n",
        "- The *bias-variance trade off* is a theorem which tells us that you\n",
        "  trade off model bias for variance and vice-versa, in practice we try\n",
        "  to find a happy medium between the two\n",
        "  - (Formally, the bias variance tradeoff concerns the behaivour of\n",
        "    statistical estimators, in practice in ML, we have a fuzzy idea as\n",
        "    described above, see the Deep Learning Book for the math)\n",
        "\n",
        "# Testing and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF5orXBORcT4"
      },
      "source": [
        "plt.plot(training_loss, label='train')\n",
        "plt.plot(testing_loss, label='test')\n",
        "plt.legend(loc='upper right'); plt.xlabel('epoch'); plt.ylabel('loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNU6CIyNRcT4"
      },
      "source": [
        "- When <font color=blue>training</font> a model, in order to check for overtraining, we\n",
        "  generally set aside some portion of the (labelled) data as a <font color=orange>test set</font>\n",
        "  - The <font color=orange>test set</font> is *never* used in the <font color=blue>training</font> stage\n",
        "  - The exactly split depends on how much data you have, 20% is a good\n",
        "    rough number if you really have no idea\n",
        "- We periodically check the model with the <font color=orange>test set</font>, and check to see\n",
        "  if the average loss of the <font color=blue>training</font>\n",
        "- The <font color=blue>training</font> average should follow the <font color=orange>test set</font> average, they will\n",
        "  diverge when the model starts overtraining\n",
        "\n",
        "# k-fold Cross-Validation\n",
        "- For models which can be trivially trained in a short amount of time,\n",
        "  you can also do more sophisticated checks such as k-fold\n",
        "  cross-validation\n",
        "  - Split the data into k equal sized subset, train k times, holding a\n",
        "    different subset each time, where each time training with k-1 of\n",
        "    the subsets, and using the the held out subset as the training sample\n",
        "  - You can use the properties of the k predictions as an estimator of\n",
        "    the bias and variance of the selected model (typically, you would\n",
        "    be using this to tune hyperparameters or something similar)\n",
        "- High bias models will have uniformly bad results across all test cases\n",
        "  - Always gets it wrong, but wrong in the same way across the test sets\n",
        "- High variance models will have highly divergent results between the\n",
        "  test sets\n",
        "  - Gets it wrong in unique ways across the test sets, since the\n",
        "    different sets have different exact fluctuations\n",
        "- A typical training regime could be:\n",
        "  - split into test and training, \n",
        "  - do k-fold cross-validation to find a good set of hyperparameters, \n",
        "  - train on the full training set, then \n",
        "  - check performance on the test set\n",
        "\n",
        "# Early Stopping\n",
        "\n",
        "- In deep learning, a single model can contain millions of parameters\n",
        "  and training can take days or weeks\n",
        "- In this case, sophisticated techniques aren't viable and instead, as\n",
        "  well as saving information on the loss, you also save the model weights\n",
        "- Then you check the testing-training loss as you go, and *choose* the\n",
        "  model parameters when the test and training curves begin diverging\n",
        "- This is early stopping, you stop training and take the model at a\n",
        "  point where it hasn't overtrained, rather than fully training the\n",
        "  model\n",
        "- In the case illustrated here, my solution to today's exercise,\n",
        "  the model starts overtraining after 4 or 5 epochs, so we'd use the\n",
        "  5-epoch model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qRcd9vBRcT5"
      },
      "source": [
        "# Training, Testing and Validation\n",
        "\n",
        "- One further complication, if you're also doing an extensive\n",
        "  *hyperparameter* search, you may also want to set aside a\n",
        "  `validation` set, as well as a testing and training set\n",
        "  - *hyperparameters* are parameters used in training the model, which\n",
        "    could be the loss rate of the SGD, the number of nodes, or even\n",
        "    switching in and out different types of models\n",
        "- In an extensive hyperparameter search, you could also be implicitly\n",
        "  tuning to the testing set, since you're using the testing results as a\n",
        "  goodness-of-model for potentially thousands of models\n",
        "  - Thus, the model you choose might just happen to be a good fit to\n",
        "    the test set because you're comparing lots of models via the test\n",
        "    set, not because it actually generalizes well\n",
        "- Thus, the validation set is set aside and not used in the testing\n",
        "  stage, but only after you've selected your final model\n",
        "  - A truly generalizable model should also have good properties on\n",
        "    the validation set, if not, you may have fit the hyperparameters\n",
        "    to the test, rather than found a generalizable model\n",
        "- When you're searching for a good model for your problem and have\n",
        "  lots of data, also keep aside a validation dataset for a final\n",
        "  validation of your selected model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47_SDJ3-RcT6"
      },
      "source": [
        "# Testing and Training in PyTorch\n",
        "\n",
        "- In pytorch, you should set your network into training mode when\n",
        "  training, and evaluation mode when testing (or running in production)\n",
        "- The differences will become important and make more sense when we\n",
        "  start talking about *regularization* later on in the course\n",
        "  - For now, just get use to the fact that you should set the network\n",
        "    into training mode when training, and eval mode otherwise\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ifKnu5ARcT6"
      },
      "source": [
        "net.train() # set into training mode\n",
        "# do training\n",
        "net.eval() # set into evaluation mode\n",
        "# do testing, or production"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkHGt1VkRcT6"
      },
      "source": [
        "# A Typical Training Loop in PyTorch\n",
        "\n",
        "- Here is a basic training loop with a testing phase at the end of each epoch\n",
        "- Assume `net` is our neural net (or other model), `data_training` is\n",
        "  a list of `(input, label)` pairs pre-split into minibatches and\n",
        "  `data_testing` is a tuple of the test inputs and corresponding labels,\n",
        "  `optimizer` is the optimizer, `criterion` is the loss function,\n",
        "  `device` is a cuda or cpu device\n",
        "- We keep track of the running loss to compute the average over the\n",
        "  epoch and compare with the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKTODAr2RcT7"
      },
      "source": [
        "inputs_testing, labels_testing = data_testing[0].to(device), data_testing[1].to(device)\n",
        "for epoch in range(num_epochs):\n",
        "  net.train()\n",
        "  running_loss, running_correct, running_n = 0.0, 0.0, 0.0\n",
        "  for inputs, labels in data_batches:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    running_loss += loss.item() * inputs.size(0) # loss is the avg. for the batch\n",
        "    # max returns a tuple of tensors: (highest value, index of highest value)\n",
        "    running_correct += torch.sum(torch.max(outputs,1)[1] == labels.data)\n",
        "    running_n += inputs.size(0)\n",
        "    optimizer.step()\n",
        "  print(\"Train loss: {:.3f} acc: {:.3f}\".format(running_loss / running_n, running_correct / running_n))\n",
        "  net.eval()\n",
        "  outputs = net(inputs_testing)\n",
        "  loss = criterion(outputs, labels_testing)\n",
        "  print(\"Test  loss: {:.3f} acc: {:.3f}\".format(loss / inputs_testing.size(0))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWR2oHtoRcT7"
      },
      "source": [
        "# Early Stopping in PyTorch, Saving/Loading Models\n",
        "\n",
        "- In pytorch, saving a model implies saving the model weights\n",
        "  - To load the model, you create the model as normal, and then load the saved weights back in\n",
        "- To save the model weights into a file, you can use `torch.save`, which you need to pass the \"state_dict\" and a filename"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIusTeuIRcT8"
      },
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DhsMlfvRcT9"
      },
      "source": [
        "- To load the weights back in, create the model, then call `load_state_dict` with the result of `torch.load`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt6yqbSaRcT9"
      },
      "source": [
        "model = Net() # Say we have a network called `Net`\n",
        "model.load_state_dict(torch.load('model_weights.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmhNz4XBRcT-"
      },
      "source": [
        "- To implement early stopping, we can keep track of the testing loss, and save the model whenever we have the lowest currently seen loss\n",
        "- In this way, what gets saved out at the end of the run is the model state with the lowest seen training loss over the whole training\n",
        "\n",
        "One final ancilliary issue: you can build up straightfoward networks with `Sequential`, which will pass the data through one layer at a time. There are `th.nn.ReLU` and equivalent layers for the activation functions. This is limited if you want to make some of the more interesting networks we will see in the future, but in the complete example below, you can see its even useful for defining subnetworks inside a full network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxEuO3kzRcT-"
      },
      "source": [
        "# A Fisher Iris network 4 inputs -> 32 hidden layer with relu activation -> 3 outputs\n",
        "net = th.nn.Sequential(th.nn.Linear(4,32), th.nn.ReLU(), th.nn.Linear(32, 3))\n",
        "net(th.tensor([1,2,3,4.]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8YbDDG8RcT_"
      },
      "source": [
        "Here is a complete example, using the FasionMNIST dataset  with a simple CNN. As always, when running, change the data directory to somewhere you have access to. Its a nice example of overtraining. Here, instead of running for a fixed number of epochs, we run until we haven't saved the network out for 20 epochs. This is another hyperparameter sometimes called \"patience\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKedKhVyRcT_"
      },
      "source": [
        "device = 'cuda'\n",
        "import torch as th\n",
        "import torchvision as tv\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "trans = tv.transforms.ToTensor()\n",
        "train = th.utils.data.DataLoader(tv.datasets.FashionMNIST('/data/torchvision', train=True, download=True, transform=trans), batch_size=256)\n",
        "test = th.utils.data.DataLoader(tv.datasets.FashionMNIST('/data/torchvision', train=False, download=True, transform=trans), batch_size=256)\n",
        "\n",
        "class FNet(th.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # pack the conv2d+relu into a single structure\n",
        "        self.c1 = th.nn.Sequential(th.nn.Conv2d(1,8,7), th.nn.ReLU())\n",
        "        self.c2 = th.nn.Sequential(th.nn.Conv2d(8,16,5), th.nn.ReLU())\n",
        "        self.c3 = th.nn.Sequential(th.nn.Conv2d(16,32,3), th.nn.ReLU())\n",
        "        self.fc = th.nn.Linear(32*16*16,10)\n",
        "    def forward(self, x):\n",
        "        x = self.c1(x) # conv2d + relu, 22x22\n",
        "        x = self.c2(x) # 18x18\n",
        "        x = self.c3(x) # 16x16\n",
        "        x = x.view(-1, 32*16*16)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "net = FNet().to(device)\n",
        "opt = th.optim.Adam(net.parameters())\n",
        "l = th.nn.CrossEntropyLoss()\n",
        "per_epoch = defaultdict(lambda:[])\n",
        "last_save = 0\n",
        "e = 0\n",
        "while last_save < 20:\n",
        "    per_batch = defaultdict(lambda:[])\n",
        "    for images, labels in train:\n",
        "        opt.zero_grad()\n",
        "        outputs = net(images.to(device))\n",
        "        loss = l(outputs, labels.to(device))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        per_batch[\"loss\"].append(loss.item()*images.size(0))\n",
        "        per_batch[\"corr\"].append(sum(th.max(outputs,1)[1].cpu()==labels))\n",
        "        per_batch[\"n\"].append(images.size(0))\n",
        "    per_epoch[\"loss\"].append(sum(per_batch[\"loss\"])/sum(per_batch[\"n\"]))\n",
        "    per_epoch[\"acc\"].append(sum(per_batch[\"corr\"])/sum(per_batch[\"n\"]))\n",
        "    for images, labels in test:\n",
        "        outputs = net(images.to(device))\n",
        "        loss = l(outputs, labels.to(device))\n",
        "        per_batch[\"tloss\"].append(loss.item()*images.size(0))\n",
        "        per_batch[\"tcorr\"].append(sum(th.max(outputs,1)[1].cpu()==labels))\n",
        "        per_batch[\"tn\"].append(images.size(0))\n",
        "    per_epoch[\"tloss\"].append(sum(per_batch[\"tloss\"])/sum(per_batch[\"tn\"]))\n",
        "    per_epoch[\"tacc\"].append(sum(per_batch[\"tcorr\"])/sum(per_batch[\"tn\"]))\n",
        "    print(f'epoch {e:03d} : train loss {per_epoch[\"loss\"][-1]:.3f} acc {per_epoch[\"acc\"][-1]:.3f} test loss {per_epoch[\"tloss\"][-1]:.3f} acc {per_epoch[\"tacc\"][-1]:.3f}')\n",
        "    # early stopping: if we are at the best epoch (= epoch with lowest loss), save the weights\n",
        "    last_save += 1; e += 1\n",
        "    if per_epoch[\"tloss\"][-1] == min(per_epoch[\"tloss\"]):\n",
        "        print(\"  saving network\")\n",
        "        th.save(net.state_dict(), 'fnet_weights.pt')\n",
        "        last_save = 0\n",
        "print(\"done training.\")\n",
        "# reload the best weights\n",
        "net.load_state_dict(th.load('fnet_weights.pt'))\n",
        "# Make plots of the training/testing losses\n",
        "plt.plot(per_epoch[\"loss\"], label=\"train\")\n",
        "plt.plot(per_epoch[\"tloss\"], label=\"test\")\n",
        "plt.legend(loc=\"upper right\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNytZ60oRcT_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnntpi_TRcT_"
      },
      "source": [
        "# Exercises <a id=\"exercises\" />\n",
        "\n",
        "- The exercises will introduce the CIFAR100 dataset, for which, as usual, we will\n",
        "  use the `torchvision` package to download and set up a `DataLoader`,\n",
        "  another helper feature that torch provides to help us process by\n",
        "  mini-batches.\n",
        "\n",
        "Today, lets introduce a more difficult. The goal of cifar100 is to take 32x32 color images of handwritten\n",
        "digits and classify each image into one of 100 categories.\n",
        "\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgPD1f9-RcUA"
      },
      "source": [
        "import torch as th\n",
        "import torchvision as tv\n",
        "trans = tv.transforms.ToTensor()\n",
        "train = tv.datasets.CIFAR100('/data/torchvision', train=True, download=True, transform=trans)\n",
        "test = tv.datasets.CIFAR100('/data/torchvision', train=False, download=True, transform=trans)\n",
        "print(train, \"\\n\", test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY8BH54DRcUA"
      },
      "source": [
        "The dataset can be iterated over and will return one image every\n",
        "iteration. In the following cell, change the cell so that it displays\n",
        "the first five images of the dataset, and prints out the corresponding\n",
        "truth labels. You can use, for example, `matplotlib.pyplot.imshow`to\n",
        "display the images. The data is 3x32x32, but `imshow` expects the color channels to come *last*, so you will need to shuffle the axes in order to do this. Check the pytorch documentation on `permute` to do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB9pDLp8RcUA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "b073eb69-b5a0-492d-a062-4732a76a938e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for image, label in train:\n",
        "  print(image.shape,'\\n', label)\n",
        "  image2 = image.permute(1, 2, 0)  # [32, 32, 3]\n",
        "  plt.imshow(image2)\n",
        "  plt.show()  \n",
        "  break\n",
        "\n",
        "# Exercise: Update cell to display the images\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 32, 32]) \n",
            " 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4arbVhtRcUB"
      },
      "source": [
        "The CIFAR100 dataset is big, with 60,000 images, 50k training and 10k testing. Therefore, we will\n",
        "process by mini-batches, rather than updating a full gradient descent\n",
        "once every time through the dataset. In order to create mini-batches,\n",
        "we could of course collect the images together ourselves, but lets\n",
        "instead use a `DataLoader`. We can pass the dataset in, and tell how\n",
        "we want to set up the mini-batches. The dataset we downloaded is the\n",
        "correct format to simply pass into the DataLoader, but we will see\n",
        "later that we can also write our own, if we have specialized data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4EXgg4QRcUB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338,
          "referenced_widgets": [
            "ac2e80835fda4f0b9d588eac78f134de",
            "6e43488419c14bbd8bc75f2d6c4401ba",
            "c1858ad016b44907947a8d65fb12cd2b",
            "9acfbab0a8934f19968e129219d09278",
            "ee20fe47600f4e18b3c858451f964ef8",
            "31be0d57901b4499ab4236b74f24b8da",
            "552b74d1ed06449d88f60a1168f991ef",
            "f1e8fb860d664edbb3c5749f40f44462"
          ]
        },
        "outputId": "47cebf98-2d4f-4717-9200-3f37f7b162a3"
      },
      "source": [
        "import torch as th\n",
        "import torchvision as tv\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "trans = tv.transforms.ToTensor()\n",
        "train = tv.datasets.CIFAR100('/data/torchvision', train=True, download=True, transform=trans)\n",
        "test = tv.datasets.CIFAR100('/data/torchvision', train=False, download=True, transform=trans)\n",
        "print(train, \"\\n\", test)\n",
        "\n",
        "trainloader = th.utils.data.DataLoader(train, batch_size=64)\n",
        "testloader = th.utils.data.DataLoader(test, batch_size=64)\n",
        "# example of how this works, we get a tensor filled with one batch,\n",
        "# and the corresponding labels\n",
        "for images, labels in trainloader:\n",
        "  print(images.shape, labels.shape)\n",
        "  break\n",
        "\n",
        "#다시시작하기 및 모두실행이 필요하다. 종종 GPU로 바꿀때. "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /data/torchvision/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac2e80835fda4f0b9d588eac78f134de",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting /data/torchvision/cifar-100-python.tar.gz to /data/torchvision\n",
            "Files already downloaded and verified\n",
            "Dataset CIFAR100\n",
            "    Number of datapoints: 50000\n",
            "    Root location: /data/torchvision\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor() \n",
            " Dataset CIFAR100\n",
            "    Number of datapoints: 10000\n",
            "    Root location: /data/torchvision\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "torch.Size([64, 3, 32, 32]) torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trLeYW8_RcUB"
      },
      "source": [
        "Now, we're in a position to set up the network. Write a basic\n",
        "convolutional neural network which will train on the CIFAR100 using\n",
        "`torch.nn.Module`. For now, you can keep it simple, with a few convolution layers followed by a fully connected linear layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WxmKWJ7RcUB"
      },
      "source": [
        "device = 'cuda'\n",
        "\n",
        "class Net(th.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = th.nn.Conv2d(3,6,5,1,padding=1) #색깔있는 이미지는 인풋 채널이 3개\n",
        "    self.conv2 = th.nn.Conv2d(6,16,5,1,padding=0) \n",
        "\n",
        "    self.fc1 = th.nn.Linear(400,120) #인풋 잘 찾가. \n",
        "    self.fc2 = th.nn.Linear(120,84)\n",
        "    self.fc3 = th.nn.Linear(84,100)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #x = x.reshape(x.shape[0],-1)\n",
        "    x1 = th.tanh(self.conv1(x))\n",
        "    x1 = th.nn.AvgPool2d(kernel_size=2)(x1)\n",
        "    x2 = th.tanh(self.conv2(x1))\n",
        "    x2 = th.nn.AvgPool2d(kernel_size=2)(x2)\n",
        "    x2 = x2.reshape(x2.shape[0],-1)\n",
        "    # print(x2.shape)\n",
        "    x3 = self.fc1(x2)\n",
        "    x4 = self.fc2(x3)\n",
        "    x = self.fc3(x4)\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUfYA8yvRcUB"
      },
      "source": [
        "Now that we have a network, we should train it! Create a training loop\n",
        "and train the network. You'll have to think what loss to use and\n",
        "choose an optimizer. Keep track of the average loss for training and\n",
        "testing of each epoch. Remember to use the GPU! Don't be too worried about getting high accuracy for the moment, just much better than chance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvYVjpsCRcUB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b5530d0-cf17-4c5a-f7cb-25e5951c0830"
      },
      "source": [
        "\n",
        "net = Net().to(device)\n",
        "opt = th.optim.Adam(net.parameters())\n",
        "l = th.nn.CrossEntropyLoss()\n",
        "per_epoch = defaultdict(lambda:[])\n",
        "last_save = 0\n",
        "e = 0\n",
        "\n",
        "while last_save < 20:\n",
        "    per_batch = defaultdict(lambda:[])\n",
        "    for images, labels in trainloader :\n",
        "        opt.zero_grad()\n",
        "        outputs = net(images.to(device))\n",
        "        loss = l(outputs, labels.to(device))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        per_batch[\"loss\"].append(loss.item()*images.size(0))\n",
        "        per_batch[\"corr\"].append(sum(th.max(outputs,1)[1].cpu()==labels))\n",
        "        per_batch[\"n\"].append(images.size(0))\n",
        "    per_epoch[\"loss\"].append(sum(per_batch[\"loss\"])/sum(per_batch[\"n\"]))\n",
        "    per_epoch[\"acc\"].append(sum(per_batch[\"corr\"])/sum(per_batch[\"n\"]))\n",
        "    for images, labels in testloader :\n",
        "        outputs = net(images.to(device))\n",
        "        loss = l(outputs, labels.to(device))\n",
        "        per_batch[\"tloss\"].append(loss.item()*images.size(0))\n",
        "        per_batch[\"tcorr\"].append(sum(th.max(outputs,1)[1].cpu()==labels))\n",
        "        per_batch[\"tn\"].append(images.size(0))\n",
        "    per_epoch[\"tloss\"].append(sum(per_batch[\"tloss\"])/sum(per_batch[\"tn\"]))\n",
        "    per_epoch[\"tacc\"].append(sum(per_batch[\"tcorr\"])/sum(per_batch[\"tn\"]))\n",
        "    print(f'epoch {e:03d} : train loss {per_epoch[\"loss\"][-1]:.3f} acc {per_epoch[\"acc\"][-1]:.3f} test loss {per_epoch[\"tloss\"][-1]:.3f} acc {per_epoch[\"tacc\"][-1]:.3f}')\n",
        "    # early stopping: if we are at the best epoch (= epoch with lowest loss), save the weights\n",
        "    last_save += 1; e += 1\n",
        "    if per_epoch[\"tloss\"][-1] == min(per_epoch[\"tloss\"]):\n",
        "        print(\"  saving network\")\n",
        "        th.save(net.state_dict(), 'fnet_weights.pt')\n",
        "        last_save = 0\n",
        "print(\"done training.\")\n",
        "# reload the best weights\n",
        "net.load_state_dict(th.load('fnet_weights.pt'))\n",
        "# Make plots of the training/testing losses\n",
        "plt.plot(per_epoch[\"loss\"], label=\"train\")\n",
        "plt.plot(per_epoch[\"tloss\"], label=\"test\")\n",
        "plt.legend(loc=\"upper right\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 000 : train loss 3.997 acc 0.098 test loss 3.771 acc 0.137\n",
            "  saving network\n",
            "epoch 001 : train loss 3.703 acc 0.151 test loss 3.655 acc 0.158\n",
            "  saving network\n",
            "epoch 002 : train loss 3.605 acc 0.170 test loss 3.583 acc 0.174\n",
            "  saving network\n",
            "epoch 003 : train loss 3.543 acc 0.180 test loss 3.546 acc 0.179\n",
            "  saving network\n",
            "epoch 004 : train loss 3.501 acc 0.188 test loss 3.523 acc 0.183\n",
            "  saving network\n",
            "epoch 005 : train loss 3.464 acc 0.194 test loss 3.496 acc 0.187\n",
            "  saving network\n",
            "epoch 006 : train loss 3.425 acc 0.201 test loss 3.463 acc 0.193\n",
            "  saving network\n",
            "epoch 007 : train loss 3.382 acc 0.207 test loss 3.435 acc 0.200\n",
            "  saving network\n",
            "epoch 008 : train loss 3.341 acc 0.214 test loss 3.409 acc 0.203\n",
            "  saving network\n",
            "epoch 009 : train loss 3.298 acc 0.221 test loss 3.380 acc 0.209\n",
            "  saving network\n",
            "epoch 010 : train loss 3.250 acc 0.230 test loss 3.337 acc 0.217\n",
            "  saving network\n",
            "epoch 011 : train loss 3.199 acc 0.238 test loss 3.298 acc 0.224\n",
            "  saving network\n",
            "epoch 012 : train loss 3.153 acc 0.246 test loss 3.262 acc 0.231\n",
            "  saving network\n",
            "epoch 013 : train loss 3.113 acc 0.253 test loss 3.231 acc 0.237\n",
            "  saving network\n",
            "epoch 014 : train loss 3.080 acc 0.259 test loss 3.207 acc 0.241\n",
            "  saving network\n",
            "epoch 015 : train loss 3.050 acc 0.265 test loss 3.187 acc 0.243\n",
            "  saving network\n",
            "epoch 016 : train loss 3.024 acc 0.270 test loss 3.171 acc 0.246\n",
            "  saving network\n",
            "epoch 017 : train loss 3.001 acc 0.275 test loss 3.157 acc 0.249\n",
            "  saving network\n",
            "epoch 018 : train loss 2.979 acc 0.280 test loss 3.144 acc 0.251\n",
            "  saving network\n",
            "epoch 019 : train loss 2.959 acc 0.283 test loss 3.133 acc 0.253\n",
            "  saving network\n",
            "epoch 020 : train loss 2.940 acc 0.287 test loss 3.123 acc 0.255\n",
            "  saving network\n",
            "epoch 021 : train loss 2.923 acc 0.290 test loss 3.114 acc 0.256\n",
            "  saving network\n",
            "epoch 022 : train loss 2.906 acc 0.293 test loss 3.105 acc 0.258\n",
            "  saving network\n",
            "epoch 023 : train loss 2.890 acc 0.296 test loss 3.096 acc 0.260\n",
            "  saving network\n",
            "epoch 024 : train loss 2.875 acc 0.299 test loss 3.088 acc 0.261\n",
            "  saving network\n",
            "epoch 025 : train loss 2.860 acc 0.302 test loss 3.079 acc 0.262\n",
            "  saving network\n",
            "epoch 026 : train loss 2.846 acc 0.305 test loss 3.071 acc 0.265\n",
            "  saving network\n",
            "epoch 027 : train loss 2.832 acc 0.308 test loss 3.063 acc 0.266\n",
            "  saving network\n",
            "epoch 028 : train loss 2.818 acc 0.311 test loss 3.055 acc 0.269\n",
            "  saving network\n",
            "epoch 029 : train loss 2.804 acc 0.313 test loss 3.047 acc 0.273\n",
            "  saving network\n",
            "epoch 030 : train loss 2.791 acc 0.316 test loss 3.040 acc 0.274\n",
            "  saving network\n",
            "epoch 031 : train loss 2.778 acc 0.319 test loss 3.033 acc 0.276\n",
            "  saving network\n",
            "epoch 032 : train loss 2.766 acc 0.321 test loss 3.026 acc 0.276\n",
            "  saving network\n",
            "epoch 033 : train loss 2.754 acc 0.324 test loss 3.020 acc 0.278\n",
            "  saving network\n",
            "epoch 034 : train loss 2.743 acc 0.327 test loss 3.014 acc 0.279\n",
            "  saving network\n",
            "epoch 035 : train loss 2.732 acc 0.328 test loss 3.008 acc 0.279\n",
            "  saving network\n",
            "epoch 036 : train loss 2.722 acc 0.331 test loss 3.003 acc 0.279\n",
            "  saving network\n",
            "epoch 037 : train loss 2.712 acc 0.333 test loss 2.998 acc 0.281\n",
            "  saving network\n",
            "epoch 038 : train loss 2.703 acc 0.335 test loss 2.993 acc 0.282\n",
            "  saving network\n",
            "epoch 039 : train loss 2.694 acc 0.336 test loss 2.989 acc 0.283\n",
            "  saving network\n",
            "epoch 040 : train loss 2.684 acc 0.338 test loss 2.984 acc 0.283\n",
            "  saving network\n",
            "epoch 041 : train loss 2.676 acc 0.339 test loss 2.980 acc 0.285\n",
            "  saving network\n",
            "epoch 042 : train loss 2.667 acc 0.341 test loss 2.976 acc 0.285\n",
            "  saving network\n",
            "epoch 043 : train loss 2.658 acc 0.343 test loss 2.971 acc 0.287\n",
            "  saving network\n",
            "epoch 044 : train loss 2.650 acc 0.345 test loss 2.967 acc 0.289\n",
            "  saving network\n",
            "epoch 045 : train loss 2.641 acc 0.347 test loss 2.964 acc 0.291\n",
            "  saving network\n",
            "epoch 046 : train loss 2.633 acc 0.348 test loss 2.960 acc 0.291\n",
            "  saving network\n",
            "epoch 047 : train loss 2.626 acc 0.348 test loss 2.957 acc 0.293\n",
            "  saving network\n",
            "epoch 048 : train loss 2.618 acc 0.350 test loss 2.954 acc 0.294\n",
            "  saving network\n",
            "epoch 049 : train loss 2.611 acc 0.351 test loss 2.951 acc 0.295\n",
            "  saving network\n",
            "epoch 050 : train loss 2.604 acc 0.352 test loss 2.949 acc 0.295\n",
            "  saving network\n",
            "epoch 051 : train loss 2.597 acc 0.354 test loss 2.947 acc 0.294\n",
            "  saving network\n",
            "epoch 052 : train loss 2.591 acc 0.355 test loss 2.945 acc 0.294\n",
            "  saving network\n",
            "epoch 053 : train loss 2.584 acc 0.356 test loss 2.943 acc 0.294\n",
            "  saving network\n",
            "epoch 054 : train loss 2.578 acc 0.358 test loss 2.942 acc 0.294\n",
            "  saving network\n",
            "epoch 055 : train loss 2.572 acc 0.360 test loss 2.941 acc 0.295\n",
            "  saving network\n",
            "epoch 056 : train loss 2.567 acc 0.361 test loss 2.940 acc 0.295\n",
            "  saving network\n",
            "epoch 057 : train loss 2.561 acc 0.363 test loss 2.939 acc 0.295\n",
            "  saving network\n",
            "epoch 058 : train loss 2.556 acc 0.364 test loss 2.938 acc 0.295\n",
            "  saving network\n",
            "epoch 059 : train loss 2.551 acc 0.365 test loss 2.938 acc 0.296\n",
            "  saving network\n",
            "epoch 060 : train loss 2.546 acc 0.366 test loss 2.937 acc 0.296\n",
            "  saving network\n",
            "epoch 061 : train loss 2.541 acc 0.367 test loss 2.937 acc 0.297\n",
            "  saving network\n",
            "epoch 062 : train loss 2.536 acc 0.368 test loss 2.937 acc 0.297\n",
            "  saving network\n",
            "epoch 063 : train loss 2.531 acc 0.370 test loss 2.937 acc 0.297\n",
            "epoch 064 : train loss 2.527 acc 0.370 test loss 2.937 acc 0.296\n",
            "epoch 065 : train loss 2.523 acc 0.371 test loss 2.937 acc 0.296\n",
            "epoch 066 : train loss 2.518 acc 0.371 test loss 2.938 acc 0.296\n",
            "epoch 067 : train loss 2.514 acc 0.373 test loss 2.938 acc 0.296\n",
            "epoch 068 : train loss 2.510 acc 0.373 test loss 2.938 acc 0.296\n",
            "epoch 069 : train loss 2.506 acc 0.374 test loss 2.938 acc 0.296\n",
            "epoch 070 : train loss 2.502 acc 0.375 test loss 2.939 acc 0.297\n",
            "epoch 071 : train loss 2.499 acc 0.375 test loss 2.939 acc 0.296\n",
            "epoch 072 : train loss 2.495 acc 0.376 test loss 2.940 acc 0.296\n",
            "epoch 073 : train loss 2.491 acc 0.376 test loss 2.940 acc 0.296\n",
            "epoch 074 : train loss 2.488 acc 0.377 test loss 2.940 acc 0.297\n",
            "epoch 075 : train loss 2.484 acc 0.378 test loss 2.941 acc 0.298\n",
            "epoch 076 : train loss 2.481 acc 0.379 test loss 2.941 acc 0.299\n",
            "epoch 077 : train loss 2.478 acc 0.380 test loss 2.942 acc 0.300\n",
            "epoch 078 : train loss 2.474 acc 0.381 test loss 2.942 acc 0.299\n",
            "epoch 079 : train loss 2.471 acc 0.381 test loss 2.943 acc 0.299\n",
            "epoch 080 : train loss 2.468 acc 0.382 test loss 2.943 acc 0.299\n",
            "epoch 081 : train loss 2.465 acc 0.383 test loss 2.944 acc 0.299\n",
            "epoch 082 : train loss 2.462 acc 0.383 test loss 2.944 acc 0.300\n",
            "done training.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6449961110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHOvGikERcUC"
      },
      "source": [
        "Draw the loss for training and the loss for testing. Do you see the\n",
        "training loss keep going down and the testing loss at some point\n",
        "rising above the testing curve?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxhdmM7vRcUC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "3f899f22-2964-40a3-9d15-302e7389a9e5"
      },
      "source": [
        "\n",
        "net = Net().to(device)\n",
        "opt = th.optim.Adam(net.parameters())\n",
        "l = th.nn.CrossEntropyLoss()\n",
        "per_epoch = defaultdict(lambda:[])\n",
        "last_save = 0\n",
        "e = 0\n",
        "\n",
        "while last_save < 20:\n",
        "    per_batch = defaultdict(lambda:[])\n",
        "    i = 0\n",
        "    for images, labels in trainloader :\n",
        "      if i == 5 :\n",
        "        break\n",
        "        opt.zero_grad()\n",
        "        outputs = net(images.to(device))\n",
        "        loss = l(outputs, labels.to(device))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        per_batch[\"loss\"].append(loss.item()*images.size(0))\n",
        "        per_batch[\"corr\"].append(sum(th.max(outputs,1)[1].cpu()==labels))\n",
        "        per_batch[\"n\"].append(images.size(0))\n",
        "        i += 1\n",
        "        \n",
        "\n",
        "    per_epoch[\"loss\"].append(sum(per_batch[\"loss\"])/sum(per_batch[\"n\"]))\n",
        "    per_epoch[\"acc\"].append(sum(per_batch[\"corr\"])/sum(per_batch[\"n\"]))\n",
        "    \n",
        "\n",
        "    for images, labels in testloader :\n",
        "        outputs = net(images.to(device))\n",
        "        loss = l(outputs, labels.to(device))\n",
        "        per_batch[\"tloss\"].append(loss.item()*images.size(0))\n",
        "        per_batch[\"tcorr\"].append(sum(th.max(outputs,1)[1].cpu()==labels))\n",
        "        per_batch[\"tn\"].append(images.size(0))\n",
        "\n",
        "    per_epoch[\"tloss\"].append(sum(per_batch[\"tloss\"])/sum(per_batch[\"tn\"]))\n",
        "    per_epoch[\"tacc\"].append(sum(per_batch[\"tcorr\"])/sum(per_batch[\"tn\"]))\n",
        "    print(f'epoch {e:03d} : train loss {per_epoch[\"loss\"][-1]:.3f} acc {per_epoch[\"acc\"][-1]:.3f} test loss {per_epoch[\"tloss\"][-1]:.3f} acc {per_epoch[\"tacc\"][-1]:.3f}')\n",
        "    # early stopping: if we are at the best epoch (= epoch with lowest loss), save the weights\n",
        "    last_save += 1; e += 1 ; \n",
        "\n",
        "    if per_epoch[\"tloss\"][-1] == min(per_epoch[\"tloss\"]):\n",
        "        print(\"  saving network\")\n",
        "        th.save(net.state_dict(), 'fnet_weights.pt')\n",
        "        last_save = 0\n",
        "\n",
        "print(\"done training.\")\n",
        "# reload the best weights\n",
        "net.load_state_dict(th.load('fnet_weights.pt'))\n",
        "# Make plots of the training/testing losses\n",
        "plt.plot(per_epoch[\"loss\"], label=\"train\")\n",
        "plt.plot(per_epoch[\"tloss\"], label=\"test\")\n",
        "plt.legend(loc=\"upper right\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-7de2c0b5a95d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mper_epoch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mper_epoch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"corr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ws9cV1HRcUC"
      },
      "source": [
        "Rewrite the training loop, and instead of running over the whole\n",
        "dataset, only run the first 5 minibatches. Run many more epochs. Redraw the curves\n",
        "for training and testing loss. You should find that the training loss tends to 0, while the testing loss shows the nice convex pattern shown in the lecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEpmtpn_RcUC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX9kHlu-RcUC"
      },
      "source": [
        "One final challenge. Create a large network (at least a million parameters). Run training for a couple hundred epochs, and check the testing and training losses. \n",
        "\n",
        "An aside, you may find the double descent curve, where the testing loss starts off going down, goes up as expected from bias-variance, but then starts to go down again. Why this happens is still unknown, but it is commonly seen training neural networks and possibly related to the mysterious generalizability of these networks with millions of parameters. \n",
        "\n",
        "https://openai.com/blog/deep-double-descent/\n",
        "\n",
        "(Note: this exact phenomena may be difficult to acheive without BatchNorm, which we will cover later, but try to train a large network to good accuracy for CIFAR100)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBM24GfQRcUC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSWycF88RcUD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}